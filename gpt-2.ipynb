{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2 Masterpiece",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xPZ-VwYl1zuN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gvbsAJ_T5xnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install fire>=0.1.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8m0fFn-w6BSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install regex==2017.4.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0wlrQJD6GEy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install requests==2.21.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfN6hVHd6JBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install tqdm==4.31.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bkjcehcg6KBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WpBqcCX0qrH",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys, os, time\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "project_full_path = '/gdrive/My Drive/Colab Notebooks/GPT2 117M Masterpiece'\n",
        "source_path = os.path.join(project_full_path,'src')\n",
        "\n",
        "if sys.path[0] != source_path:\n",
        "    sys.path.insert(0,source_path)\n",
        "\n",
        "os.system('python -m compileall')\n",
        "\n",
        "train_path = os.path.join(source_path,'train.py')\n",
        "print(train_path)\n",
        "print(os.path.isfile(train_path))\n",
        "sample_path = os.path.join(source_path,'sample.py')\n",
        "print(sample_path)\n",
        "print(os.path.isfile(sample_path))\n",
        "encoder_path = os.path.join(source_path,'encoder.py')\n",
        "print(encoder_path)\n",
        "print(os.path.isfile(encoder_path))\n",
        "model_path = os.path.join(source_path,'model.py')\n",
        "print(model_path)\n",
        "print(os.path.isfile(model_path))\n",
        "print(os.path.isfile(train_path) and os.path.isfile(model_path) and os.path.isfile(encoder_path) and os.path.isfile(sample_path))\n",
        "\n",
        "dataset_path = 'dataset'\n",
        "model_name = '117M'\n",
        "seed = 23091996\n",
        "batch_size = 1\n",
        "sample_length = 1024\n",
        "sample_number = 1\n",
        "sample_every = 1000\n",
        "run_name = 'default'\n",
        "restore_from_checkpoint = 'latest'\n",
        "save_model_checkpoint_every = 1000\n",
        "\n",
        "print('Waiting for directory to mount...')\n",
        "while not(os.path.isdir(source_path)):\n",
        "    pass\n",
        "print('Waiting for source files to be recognized...')\n",
        "while not(os.path.isfile(train_path) and os.path.isfile(model_path) and os.path.isfile(encoder_path) and os.path.isfile(sample_path)):\n",
        "    pass\n",
        "#print('Waiting for bytecode to compile...')\n",
        "#while not(os.path.isdir(os.path.join(source_path,'__pycache__'))):\n",
        "#    pass\n",
        "\n",
        "import train\n",
        "\n",
        "train.train_main(\n",
        "    project_full_path,\n",
        "    dataset_path,\n",
        "    model_name,\n",
        "    seed,\n",
        "    batch_size,\n",
        "    sample_length,\n",
        "    sample_number,\n",
        "    sample_every,\n",
        "    run_name,\n",
        "    restore_from_checkpoint,\n",
        "    save_model_checkpoint_every)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}